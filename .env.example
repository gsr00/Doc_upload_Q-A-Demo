# Copy this file to ".env" and fill in your secrets before running with real LLMs.
# Not required while the LLM gateway is still in placeholder mode.

# OpenAI (or compatible) API key
OPENAI_API_KEY=your-openai-api-key

# Optional: override the default model (defaults to gpt-4o-mini if unset)
OPENAI_MODEL=gpt-4o-mini

# Optional: override the API base if you use a proxy
# OPENAI_API_BASE=https://api.openai.com/v1/chat/completions

# Optional: embedding model settings
OPENAI_EMBED_MODEL=text-embedding-3-small
# Optional: override embeddings endpoint
# OPENAI_EMBED_API_BASE=https://api.openai.com/v1/embeddings
# Optional: force embedding vector size to match your index (e.g., 1024)
# EMBEDDING_DIM=1024

# Local path where source DOCX files live for search excerpts
# RAG_DOC_ROOT=C:\path\to\documents
# Minimum similarity score for document Q&A
# MIN_RELEVANCE_SCORE=0.35

# Pinecone
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_INDEX=your-index-name
# Optional: supply host to skip index lookup
# PINECONE_HOST=https://your-index-host
